import express, { Request, Response } from "express";
import dotenv from "dotenv";
import { GoogleGenerativeAI } from "@google/generative-ai";
import multer from "multer";
import FormData from "form-data";
import fetch from "node-fetch";
import fs from "fs";
import path from "path";

dotenv.config();

const app = express();
app.use(express.text());

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY as string);

// Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
const model = genAI.getGenerativeModel({
  model: "models/gemini-2.0-flash-thinking-exp-01-21",
  generationConfig: {
    temperature: 0.95,
    topP: 0.95,
    topK: 64,
    maxOutputTokens: 65536,
  },
});

const upload = multer({ dest: "uploads/" });

app.post("/speech-to-text", upload.single("file"), async (req: Request, res: Response): Promise<void> => {
  try {
    if (!req.file) {
      res.status(400).json({ error: "No file uploaded" });
      return;
    }

    const apiKey = "sk_2c72d7f245eb039de0857a2311c986fcc3d4e144940c2a6e";
    const apiUrl = "https://api.elevenlabs.io/v1/speech-to-text";

    const form = new FormData();
    form.append("model_id", "scribe_v1_experimental");
    form.append("file", fs.createReadStream(req.file.path), {
      filename: req.file.originalname,
      contentType: req.file.mimetype,
    });

    const response = await fetch(apiUrl, {
      method: "POST",
      headers: {
        "xi-api-key": apiKey,
        ...form.getHeaders(),
      },
      body: form as any,
    });

    const data = await response.json();

    // Clean up uploaded file
    fs.unlink(req.file.path, () => {});

    res.json(data);
  } catch (err: any) {
    res.status(500).json({ error: err.message || "Something went wrong" });
  }
});

app.post("/generate", async (req: Request, res: Response) => {
  const userInput = req.body;
  // 1. Define the contents array
  const contents = [
    {
      role: "user",
      parts: [
        {
          text: `Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ù…Ø¹ Ø§Ù„ÙˆÙ‚Øª :

[
  {
    "wordsTimes": [
      {
        "text": "Ø£ÙŠ",
        "start": 20.259
      },
      {
        "text": " ",
        "start": 20.579
      },
      {
        "text": "Ø­Ù„Ù…",
        "start": 20.579
      },
      {
        "text": " ",
        "start": 21.039
      },
      {
        "text": "Ù…ÙØ¬Ø¹.",
        "start": 21.379
      },
      {
        "text": " ",
        "start": 21.999
      },
      {
        "text": "ØªØ³Ù„Ù„",
        "start": 22.899
      },
      {
        "text": " ",
        "start": 23.519
      },
      {
        "text": "Ù„Ø¬ÙÙ†Ù‡Ø§.",
        "start": 23.619
      },
      {
        "text": " ",
        "start": 24.839
      },
      {
        "text": "ØªÙ„Ùƒ",
        "start": 25.76
      },
      {
        "text": " ",
        "start": 26.279
      },
      {
        "text": "Ø§Ù„Ù…Ø«Ù‚Ù„Ø©",
        "start": 26.359
      },
      {
        "text": " ",
        "start": 27.399
      },
      {
        "text": "Ø¨Ø¢Ù„Ø§Ù…",
        "start": 28.279
      },
      {
        "text": " ",
        "start": 29.099
      },
      {
        "text": "Ø§Ù„Ù…Ø±Ø¶",
        "start": 29.099
      },
      {
        "text": " ",
        "start": 30.039
      },
      {
        "text": "ÙˆØ§Ù„ÙØ±Ø§Ù‚.",
        "start": 30.039
      },
      {
        "text": " ",
        "start": 30.959
      },
      {
        "text": "ÙÙŠ",
        "start": 31.239
      },
      {
        "text": " ",
        "start": 31.699
      },
      {
        "text": "Ù„ÙŠÙ„Ø©",
        "start": 31.719
      },
      {
        "text": " ",
        "start": 32.44
      },
      {
        "text": "Ø¯Ù…Ø¹",
        "start": 32.559
      },
      {
        "text": " ",
        "start": 33.139
      },
      {
        "text": "Ø¬Ø§Ù†Øª",
        "start": 33.459
      },
      {
        "text": " ",
        "start": 34.279
      },
      {
        "text": "Ø«Ù‚ÙŠÙ„Ø©.",
        "start": 34.319
      },
      {
        "text": " ",
        "start": 35.919
      },
      {
        "text": "ÙØ²Øª",
        "start": 36.719
      },
      {
        "text": " ",
        "start": 37.379
      },
      {
        "text": "Ù…Ù†",
        "start": 37.42
      },
      {
        "text": " ",
        "start": 37.78
      },
      {
        "text": "Ø­Ù„ÙŠÙ…",
        "start": 37.84
      },
      {
        "text": " ",
        "start": 38.819
      },
      {
        "text": "Ø¹ÙŠÙ†Ù‰",
        "start": 38.819
      },
      {
        "text": " ",
        "start": 39.619
      },
      {
        "text": "Ø§Ù„Ø¹Ù„ÙŠÙ„Ù‰.",
        "start": 39.619
      },
      {
        "text": " ",
        "start": 41.139
      },
      {
        "text": "Ù„Ù…Ø­Øª",
        "start": 42.079
      },
      {
        "text": " ",
        "start": 42.799
      },
      {
        "text": "ÙˆØ¬Ù‡",
        "start": 42.799
      },
      {
        "text": " ",
        "start": 43.479
      },
      {
        "text": "Ù„ÙŠØ­Ø³Ø§Ù†",
        "start": 43.479
      },
      {
        "text": " ",
        "start": 44.699
      },
      {
        "text": "Ø¨Ù…Ù†",
        "start": 44.799
      },
      {
        "text": " ",
        "start": 45.239
      },
      {
        "text": "ÙŠØªÙŠ.",
        "start": 45.239
      },
      {
        "text": " ",
        "start": 46.659
      },
      {
        "text": "Ø±Ø§Ø¯Øª",
        "start": 47.399
      },
      {
        "text": " ",
        "start": 48.059
      },
      {
        "text": "ÙˆØ¯Ø¹Ù‡",
        "start": 48.059
      },
      {
        "text": " ",
        "start": 48.86
      },
      {
        "text": "Ø¨Ø³Ø§Ø¹Ø©",
        "start": 49.36
      },
      {
        "text": " ",
        "start": 50.299
      },
      {
        "text": "Ø±Ø­ÙŠÙ„.",
        "start": 50.38
      },
      {
        "text": " ",
        "start": 51.46
      },
      {
        "text": "ÙˆØ±Ø¯Ø©",
        "start": 52.459
      },
      {
        "text": " ",
        "start": 53.08
      },
      {
        "text": "ÙˆØ±ÙƒØ¶Øª",
        "start": 53.2
      },
      {
        "text": " ",
        "start": 54.08
      },
      {
        "text": "Ù…Ø·Ø±Ø©",
        "start": 54.639
      },
      {
        "text": " ",
        "start": 55.5
      },
      {
        "text": "Ø­Ù†ÙŠÙ†Ø©.",
        "start": 55.5
      },
      {
        "text": " ",
        "start": 57.039
      },
      {
        "text": "Ù…Ø³Ø­Ø©",
        "start": 57.939
      },
      {
        "text": " ",
        "start": 58.459
      },
      {
        "text": "Ø¯Ù…Ø¹Ø©",
        "start": 58.599
      },
      {
        "text": " ",
        "start": 59.259
      },
      {
        "text": "Ù…ÙŠÙ„.",
        "start": 59.259
      },
      {
        "text": " ",
        "start": 59.959
      },
      {
        "text": "ØªÙ…",
        "start": 60
      },
      {
        "text": " ",
        "start": 60.579
      },
      {
        "text": "Ø¹Ù„ÙŠÙ†Ø§",
        "start": 60.599
      },
      {
        "text": " ",
        "start": 62.339
      },
      {
        "text": "Ù…Ù†",
        "start": 63.299
      },
      {
        "text": " ",
        "start": 63.579
      },
      {
        "text": "Ø´Ø§ÙØª",
        "start": 63.599
      },
      {
        "text": " ",
        "start": 64.219
      },
      {
        "text": "Ø±Ù…Ø­",
        "start": 64.379
      },
      {
        "text": " ",
        "start": 64.959
      },
      {
        "text": "Ø¨Ø§Ø®Ø±",
        "start": 65.259
      },
      {
        "text": " ",
        "start": 65.979
      },
      {
        "text": "Ù„Ø­ÙŠØªÙ‡Ø§.",
        "start": 66.239
      },
      {
        "text": " ",
        "start": 67.679
      },
      {
        "text": "Ø±ÙƒØ¶Øª",
        "start": 68.639
      },
      {
        "text": " ",
        "start": 69.119
      },
      {
        "text": "ÙˆÙˆØ±Ø¯Øª",
        "start": 69.419
      },
      {
        "text": " ",
        "start": 70.24
      },
      {
        "text": "Ø¹Ù†",
        "start": 70.759
      },
      {
        "text": " ",
        "start": 71.039
      },
      {
        "text": "Ø¬Ø³Ù…Ù‡",
        "start": 71.079
      },
      {
        "text": " ",
        "start": 71.639
      },
      {
        "text": "ÙˆÙŠØ¯Ù‡.",
        "start": 71.659
      },
      {
        "text": " ",
        "start": 73.06
      },
      {
        "text": "ØªØµØ±Ø®",
        "start": 73.619
      },
      {
        "text": " ",
        "start": 74.439
      },
      {
        "text": "Ø¨Ø§Ù„Ø­Ù†ÙŠÙ†.",
        "start": 74.5
      },
      {
        "text": " ",
        "start": 75.979
      },
      {
        "text": "ØµØ±Ø§Ø®",
        "start": 77.119
      },
      {
        "text": " ",
        "start": 78.119
      },
      {
        "text": "Ø£Ù…ÙˆØ§Øª",
        "start": 78.259
      },
      {
        "text": " ",
        "start": 80.139
      },
      {
        "text": "Ø£Ù„Ù…",
        "start": 80.659
      },
      {
        "text": " ",
        "start": 81.259
      },
      {
        "text": "ÙˆØ§Ù‡Ø§Øª.",
        "start": 81.559
      },
      {
        "text": " ",
        "start": 83.759
      },
      {
        "text": "Ø¨Ø³Ù…Ø©",
        "start": 84.239
      },
      {
        "text": " ",
        "start": 84.919
      },
      {
        "text": "ÙŠÙ†Ø³Ù…Ø¹",
        "start": 85.099
      },
      {
        "text": " ",
        "start": 86.439
      },
      {
        "text": "Ø³Ø¯ÙŠ.",
        "start": 87.68
      },
      {
        "text": " ",
        "start": 88.399
      },
      {
        "text": "ÙˆÙŠÙ†Ù‡Ø¯Ù…",
        "start": 88.479
      },
      {
        "text": " ",
        "start": 90.86
      },
      {
        "text": "Ø¬ÙÙ†Ù‡Ø§",
        "start": 91.239
      },
      {
        "text": " ",
        "start": 92.379
      },
      {
        "text": "Ø§Ù„Ø°Ø§Øª.",
        "start": 92.4
      },
      {
        "text": " ",
        "start": 94.059
      },
      {
        "text": "Ù†Ø¸Ø±Ù‡Ø§",
        "start": 94.779
      },
      {
        "text": " ",
        "start": 95.8
      },
      {
        "text": "Ø§Ù„ØºØ§Ø¨.",
        "start": 95.819
      },
      {
        "text": " ",
        "start": 97
      },
      {
        "text": "ÙˆÙŠ",
        "start": 98.299
      },
      {
        "text": " ",
        "start": 98.739
      },
      {
        "text": "Ù…ÙˆØ¬",
        "start": 98.759
      },
      {
        "text": " ",
        "start": 99.399
      },
      {
        "text": "Ø§Ù„Ø¯Ù…ÙŠØ¹.",
        "start": 99.4
      },
      {
        "text": " ",
        "start": 101.159
      },
      {
        "text": "ØµÙˆØª",
        "start": 101.379
      },
      {
        "text": " ",
        "start": 102.18
      },
      {
        "text": "ØµÙˆØª",
        "start": 102.259
      },
      {
        "text": " ",
        "start": 103.119
      },
      {
        "text": "Ù…Ø§",
        "start": 103.619
      },
      {
        "text": " ",
        "start": 103.959
      },
      {
        "text": "ÙŠÙ„ØªÙ…Ù…",
        "start": 103.959
      },
      {
        "text": " ",
        "start": 104.7
      },
      {
        "text": "Ø¨Ù‡ÙˆØ§Ù‡Ø§.",
        "start": 104.739
      },
      {
        "text": " ",
        "start": 106.219
      },
      {
        "text": "Ù…ÙˆØª.",
        "start": 106.699
      },
      {
        "text": " ",
        "start": 107.599
      },
      {
        "text": "Ù…ÙˆØª.",
        "start": 107.599
      },
      {
        "text": " ",
        "start": 108.539
      },
      {
        "text": "ØªØ­ÙƒÙŠ.",
        "start": 108.9
      },
      {
        "text": " ",
        "start": 109.4
      },
      {
        "text": "ÙŠØ±Ø¯",
        "start": 109.72
      },
      {
        "text": " ",
        "start": 110.139
      },
      {
        "text": "ØµØ¯Ø§Ù‡Ø§.",
        "start": 110.22
      },
      {
        "text": " ",
        "start": 111.599
      },
      {
        "text": "ØªØµØ±Ø®",
        "start": 112.619
      },
      {
        "text": " ",
        "start": 113.3
      },
      {
        "text": "Ø¨Ø§Ù„Ø­Ù†ÙŠÙ†.",
        "start": 113.379
      },
      {
        "text": " ",
        "start": 114.519
      },
      {
        "text": "ØªØµØ±Ø®",
        "start": 115.959
      },
      {
        "text": " ",
        "start": 116.819
      },
      {
        "text": "Ø¨Ø§Ù„Ø­Ù†ÙŠÙ†.",
        "start": 116.839
      },
      {
        "text": " ",
        "start": 119.119
      },
      {
        "text": "ØµÙˆØª",
        "start": 121.899
      },
      {
        "text": " ",
        "start": 122.739
      },
      {
        "text": "ØµÙˆØª.",
        "start": 122.799
      },
      {
        "text": " ",
        "start": 123.719
      },
      {
        "text": "Ù…Ø§",
        "start": 124.18
      },
      {
        "text": " ",
        "start": 124.419
      },
      {
        "text": "ÙŠÙ„ØªÙ…Ù….",
        "start": 124.519
      },
      {
        "text": " ",
        "start": 125.46
      },
      {
        "text": "Ø¨ÙˆØ§Ù‡Ø©.",
        "start": 125.519
      },
      {
        "text": " ",
        "start": 126.82
      },
      {
        "text": "Ù…ÙˆØª.",
        "start": 127.239
      },
      {
        "text": " ",
        "start": 128.259
      },
      {
        "text": "Ù…ÙˆØª.",
        "start": 129.419
      },
      {
        "text": " ",
        "start": 129.439
      },
      {
        "text": "ØªØ­Ø¬ÙŠ.",
        "start": 129.459
      },
      {
        "text": " ",
        "start": 129.979
      },
      {
        "text": "ÙˆÙŠØ±Ø¯.",
        "start": 130.079
      },
      {
        "text": " ",
        "start": 130.779
      },
      {
        "text": "ØµØ¯Ø§Ù‡Ø§.",
        "start": 130.799
      },
      {
        "text": " ",
        "start": 132.4
      },
      {
        "text": "ØªØµØ±Ø®",
        "start": 133.18
      },
      {
        "text": " ",
        "start": 133.86
      },
      {
        "text": "Ø¨Ø§Ù„Ø­Ù†ÙŠÙ†.",
        "start": 133.939
      },
      {
        "text": " ",
        "start": 135.159
      },
      {
        "text": "ØªØµØ±Ø®",
        "start": 136.519
      },
      {
        "text": " ",
        "start": 137.379
      },
      {
        "text": "Ø¨Ø§Ù„Ø­Ù†ÙŠÙ†.",
        "start": 137.399
      }
    ]
  }
]

Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø© Ù„ØºÙˆÙŠØ§ :
\\ÙÙŠ Ù„ÙŠÙ„Ø© Ø¯Ù…Ø¹ Ø¬Ø§Ù†Øª Ø«Ú¯ÙŠÙ„Ù‡
ÙØ²Øª Ù…Ù† Ø­Ù„Ù… Ø¹ÙŠÙ† Ø§Ù„Ø¹Ù„ÙŠÙ„Ø©
Ù„Ù…Ø­Øª ÙˆØ¬Ù‡ Ø§Ù„Ø­Ø³ÙŠÙ† Ø¨Ù…Ù†ÙŠØªÙ‡
Ø±Ø§Ø¯ ØªÙˆØ¯Ø¹Ù‡ Ø¨Ø³Ø§Ø¹Ø© Ø±Ø­ÙŠÙ„Ù‡
ÙˆØ±Ø¯Ù‡ ÙˆØ±ÙƒØ¶Øª Ù„Ù…Ø·Ø±Ø© Ø­Ù†ÙŠÙ†Ù‡
Ù…Ø³Ø­Øª Ø¯Ù…Ø¹Ù‡ Ù…Ù„ØªÙ…Ù‡ Ø§Ø¹Ù„Ù‡ Ø¹ÙŠÙ†Ù‡
Ù…Ù† Ø´Ø§ÙØª Ø±Ù…Ø­ Ø¨Ø¢Ø®Ø± Ù„Ø­ÙŠØªÙ‡
Ø±ÙƒØ¶Øª Ø¯ÙˆØ±Øª Ø¹Ù† Ø¬Ø³Ù…Ù‡ ÙˆÙŠÙ†Ù‡
ØªØµØ±Ø® Ø¨Ø§Ù„Ø­Ù„Ù… 
ØµØ±Ø§Ø® Ø§Ù…ÙˆØ§Øª    Ø§Ù„Ù… ÙˆØ§Ù‡Ø§Øª    Ø¨Ø³ Ù…Ø§ ÙŠÙ†Ø³Ù…Ø¹
Ø³Ø¯ ÙˆÙŠÙ†Ù‡Ø¯Ù…
Ú†ÙÙ†Ù‡Ø§ Ø§Ù„Ø°Ø§Ø¨    Ù†Ø¸Ø±Ù‡Ø§ Ø§Ù„ØºØ§Ø¨    ÙˆÙŠ Ù…ÙˆØ¬ Ø§Ù„Ø¯Ù…Ø¹
ØµÙˆØª ØµÙˆØª .. Ù…Ø§ ÙŠÙ„ØªÙ… Ø¨Ù‡ÙˆØ§Ù‡Ø§
Ù…ÙˆØª Ù…ÙˆØª .. ØªØ­Ú†ÙŠ ÙˆÙŠØ±Ø¯ ØµØ¯Ø§Ù‡Ø§
ØªØµØ±Ø® Ø¨Ø§Ù„Ø­Ù„Ù…

Ø§Ù„Ø§Ø®Ø±Ø§Ø¬ ÙŠØ¬Ø¨ Ø§Ù† ÙŠÙƒÙˆÙ† :
[00:31.23]ÙÙŠ Ù„ÙŠÙ„Ø© Ø¯Ù…Ø¹ Ø¬Ø§Ù†Øª Ø«Ú¯ÙŠÙ„Ù‡
[00:36.71]ÙØ²Øª Ù…Ù† Ø­Ù„Ù… Ø¹ÙŠÙ† Ø§Ù„Ø¹Ù„ÙŠÙ„Ø©
[00:42.07]Ù„Ù…Ø­Øª ÙˆØ¬Ù‡ Ø§Ù„Ø­Ø³ÙŠÙ† Ø¨Ù…Ù†ÙŠØªÙ‡
[00:47.39]Ø±Ø§Ø¯ ØªÙˆØ¯Ø¹Ù‡ Ø¨Ø³Ø§Ø¹Ø© Ø±Ø­ÙŠÙ„Ù‡
[00:52.45]ÙˆØ±Ø¯Ù‡ ÙˆØ±ÙƒØ¶Øª Ù„Ù…Ø·Ø±Ø© Ø­Ù†ÙŠÙ†Ù‡
[00:57.93]Ù…Ø³Ø­Øª Ø¯Ù…Ø¹Ù‡ Ù…Ù„ØªÙ…Ù‡ Ø§Ø¹Ù„Ù‡ Ø¹ÙŠÙ†Ù‡
[01:03.29]Ù…Ù† Ø´Ø§ÙØª Ø±Ù…Ø­ Ø¨Ø¢Ø®Ø± Ù„Ø­ÙŠØªÙ‡
[01:08.63]Ø±ÙƒØ¶Øª Ø¯ÙˆØ±Øª Ø¹Ù† Ø¬Ø³Ù…Ù‡ ÙˆÙŠÙ†Ù‡
[01:13.61]ØªØµØ±Ø® Ø¨Ø§Ù„Ø­Ù„Ù…
[01:17.11]ØµØ±Ø§Ø® Ø§Ù…ÙˆØ§Øª Ø§Ù„Ù… ÙˆØ§Ù‡Ø§Øª Ø¨Ø³ Ù…Ø§ ÙŠÙ†Ø³Ù…Ø¹
[01:27.68]Ø³Ø¯ ÙˆÙŠÙ†Ù‡Ø¯Ù…
[01:31.23]Ú†ÙÙ†Ù‡Ø§ Ø§Ù„Ø°Ø§Ø¨ Ù†Ø¸Ø±Ù‡Ø§ Ø§Ù„ØºØ§Ø¨ ÙˆÙŠ Ù…ÙˆØ¬ Ø§Ù„Ø¯Ù…Ø¹
[01:41.37]ØµÙˆØª ØµÙˆØª .. Ù…Ø§ ÙŠÙ„ØªÙ… Ø¨Ù‡ÙˆØ§Ù‡Ø§
[01:46.69]Ù…ÙˆØª Ù…ÙˆØª .. ØªØ­Ú†ÙŠ ÙˆÙŠØ±Ø¯ ØµØ¯Ø§Ù‡Ø§
[01:52.61]ØªØµØ±Ø® Ø¨Ø§Ù„Ø­Ù„Ù…



`,
        },
      ],
    },
    {
      role: "model",
      parts: [
        {
          text: `Here's a thinking process to arrive at the desired LRC format output:

1.  **Understand the Goal:** The user wants to convert a JSON structure containing words and their start times into an LRC (LyRiCs) format. The LRC format uses \`[mm:ss.xx]\` timestamps followed by the corresponding lyric line. Crucially, the user provides a "linguistically accurate" version of the lyrics, which should be used instead of the raw text from the JSON. The output should group the words from the JSON based on the lines provided in the accurate lyrics and assign the start time of the *first* word of that line as the timestamp for the entire line.

2.  **Input Data Analysis:**
    *   **JSON Input (\`wordsTimes\`):** An array of objects, each containing a \`text\` (word or space) and a \`start\` time (in seconds).
    *   **Accurate Lyrics:** A block of text representing the correct lines of the song/poem.
    *   **Desired Output (LRC Format):** Lines of text prefixed with \`[mm:ss.xx]\`.

3.  **Core Task:** Match the words in the JSON input to the lines in the accurate lyrics and generate the LRC output.

4.  **Strategy:**
    *   **Preprocessing:**
        *   Clean the JSON \`wordsTimes\` data: Remove objects representing only spaces (\`"text": " "\`). Concatenate consecutive non-space words until a space is encountered or the end is reached. This simplifies matching later. *Correction:* Looking at the provided accurate lyrics and the desired output, it seems the JSON already represents words (sometimes including punctuation) separated by spaces. The task is less about concatenation and more about *mapping* sequences of JSON words to the accurate lyric lines.
        *   Clean the accurate lyrics: Split the accurate lyrics into individual lines. Trim whitespace from each line.
    *   **Matching and Timestamping:**
        *   Iterate through the accurate lyric lines one by one.
        *   For each accurate line, find the corresponding sequence of words in the (cleaned) JSON data.
        *   The *start time* for the LRC line will be the \`start\` time of the *first* word in the matched sequence from the JSON.
        *   Format the start time into \`[mm:ss.xx\`.
        *   Construct the LRC line: \`[mm:ss.xx]Accurate Lyric Line Text\`.
    *   **Handling Mismatches/Challenges:**
        *   The JSON text might have slight variations (e.g., spelling, punctuation) compared to the accurate lyrics. A robust matching mechanism is needed. Simple string comparison might fail. A word-by-word comparison, perhaps ignoring minor punctuation differences, might be better.
        *   The JSON might contain extra words or filler sounds not present in the accurate lyrics. These should likely be skipped.
        *   The JSON might *miss* words present in the accurate lyrics. This is harder to handle automatically and might require manual adjustment or a more sophisticated alignment algorithm. *Self-correction:* The user *provided* the target output, which implies the mapping is already implicitly defined. The task is to find the *start time* for each *target line* based on the *first word* of that line as it appears (even if slightly differently spelled) in the JSON.

5.  **Refined Strategy (Based on Provided Example):**
    *   Take the first accurate lyric line: "ÙÙŠ Ù„ÙŠÙ„Ø© Ø¯Ù…Ø¹ Ø¬Ø§Ù†Øª Ø«Ú¯ÙŠÙ„Ù‡"
    *   Find the *start* of this phrase in the JSON \`wordsTimes\`. Look for the first word "ÙÙŠ".
    *   In the JSON: \`{"text": "ÙÙŠ", "start": 31.239}\`. This looks like the start.
    *   Confirm the subsequent words roughly match: "Ù„ÙŠÙ„Ø©", "Ø¯Ù…Ø¹", "Ø¬Ø§Ù†Øª", "Ø«Ù‚ÙŠÙ„Ø©." (JSON has "Ø«Ù‚ÙŠÙ„Ø©."). The match seems good enough.
    *   The timestamp for this line is the start time of "ÙÙŠ": \`31.239\`.
    *   Format the timestamp: \`31.239\` seconds = 00 minutes, 31.23 seconds. Format as \`[00:31.23]\`. *User example uses \`[00:31.23]\`. Let's stick to two decimal places.*
    *   Construct the first LRC line: \`[00:31.23]ÙÙŠ Ù„ÙŠÙ„Ø© Ø¯Ù…Ø¹ Ø¬Ø§Ù†Øª Ø«Ú¯ÙŠÙ„Ù‡\`

    *   Take the second accurate lyric line: "ÙØ²Øª Ù…Ù† Ø­Ù„Ù… Ø¹ÙŠÙ† Ø§Ù„Ø¹Ù„ÙŠÙ„Ø©"
    *   Find the start of this phrase in the JSON. Look for "ÙØ²Øª".
    *   In the JSON: \`{"text": "ÙØ²Øª", "start": 36.719}\`.
    *   Confirm subsequent words: "Ù…Ù†", "Ø­Ù„ÙŠÙ…" (JSON) vs "Ø­Ù„Ù…" (accurate), "Ø¹ÙŠÙ†Ù‰" (JSON) vs "Ø¹ÙŠÙ†" (accurate), "Ø§Ù„Ø¹Ù„ÙŠÙ„Ù‰." (JSON) vs "Ø§Ù„Ø¹Ù„ÙŠÙ„Ø©" (accurate). The match is close enough given the context.
    *   Timestamp: \`36.719\`. Format: \`[00:36.71]\`. *User example uses \`[00:36.71]\`. Okay.*
    *   Construct the second LRC line: \`[00:36.71]ÙØ²Øª Ù…Ù† Ø­Ù„Ù… Ø¹ÙŠÙ† Ø§Ù„Ø¹Ù„ÙŠÙ„Ø©\`

    *   Take the third accurate lyric line: "Ù„Ù…Ø­Øª ÙˆØ¬Ù‡ Ø§Ù„Ø­Ø³ÙŠÙ† Ø¨Ù…Ù†ÙŠØªÙ‡"
    *   Find "Ù„Ù…Ø­Øª" in the JSON.
    *   In the JSON: \`{"text": "Ù„Ù…Ø­Øª", "start": 42.079}\`.
    *   Subsequent words: "ÙˆØ¬Ù‡", "Ù„ÙŠØ­Ø³Ø§Ù†" (JSON) vs "Ø§Ù„Ø­Ø³ÙŠÙ†" (accurate), "Ø¨Ù…Ù†" (JSON) vs "Ø¨Ù€" (implied in accurate?), "ÙŠØªÙŠ." (JSON) vs "Ù…Ù†ÙŠØªÙ‡" (accurate). Significant difference here ("Ù„ÙŠØ­Ø³Ø§Ù†" vs "Ø§Ù„Ø­Ø³ÙŠÙ†", "Ø¨Ù…Ù† ÙŠØªÙŠ." vs "Ø¨Ù…Ù†ÙŠØªÙ‡"). However, the *starting word* "Ù„Ù…Ø­Øª" is clear.
    *   Timestamp: \`42.079\`. Format: \`[00:42.07]\`. *User example uses \`[00:42.07]\`. Okay.*
    *   Construct the third LRC line: \`[00:42.07]Ù„Ù…Ø­Øª ÙˆØ¬Ù‡ Ø§Ù„Ø­Ø³ÙŠÙ† Ø¨Ù…Ù†ÙŠØªÙ‡\`

    *   Continue this process for all lines:
        *   "Ø±Ø§Ø¯ ØªÙˆØ¯Ø¹Ù‡ Ø¨Ø³Ø§Ø¹Ø© Ø±Ø­ÙŠÙ„Ù‡" -> Find "Ø±Ø§Ø¯Øª" (\`47.399\`) -> \`[00:47.39]\`
        *   "ÙˆØ±Ø¯Ù‡ ÙˆØ±ÙƒØ¶Øª Ù„Ù…Ø·Ø±Ø© Ø­Ù†ÙŠÙ†Ù‡" -> Find "ÙˆØ±Ø¯Ø©" (\`52.459\`) -> \`[00:52.45]\` (User example \`[00:52.45]\`)
        *   "Ù…Ø³Ø­Øª Ø¯Ù…Ø¹Ù‡ Ù…Ù„ØªÙ…Ù‡ Ø§Ø¹Ù„Ù‡ Ø¹ÙŠÙ†Ù‡" -> Find "Ù…Ø³Ø­Ø©" (\`57.939\`) -> \`[00:57.93]\` (User example \`[00:57.93]\`)
        *   "Ù…Ù† Ø´Ø§ÙØª Ø±Ù…Ø­ Ø¨Ø¢Ø®Ø± Ù„Ø­ÙŠØªÙ‡" -> Find "Ù…Ù†" (\`63.299\`) -> \`[01:03.29]\` (User example \`[01:03.29]\`)
        *   "Ø±ÙƒØ¶Øª Ø¯ÙˆØ±Øª Ø¹Ù† Ø¬Ø³Ù…Ù‡ ÙˆÙŠÙ†Ù‡" -> Find "Ø±ÙƒØ¶Øª" (\`68.639\`) -> \`[01:08.63]\` (User example \`[01:08.63]\`)
        *   "ØªØµØ±Ø® Ø¨Ø§Ù„Ø­Ù„Ù…" -> Find "ØªØµØ±Ø®" (\`73.619\`) -> \`[01:13.61]\` (User example \`[01:13.61]\`). *Note: The JSON has "ØªØµØ±Ø® Ø¨Ø§Ù„Ø­Ù†ÙŠÙ†." here.* We use the accurate text.
        *   "ØµØ±Ø§Ø® Ø§Ù…ÙˆØ§Øª Ø§Ù„Ù… ÙˆØ§Ù‡Ø§Øª Ø¨Ø³ Ù…Ø§ ÙŠÙ†Ø³Ù…Ø¹" -> Find "ØµØ±Ø§Ø®" (\`77.119\`) -> \`[01:17.11]\` (User example \`[01:17.11]\`). *Note: The JSON breaks this down: "ØµØ±Ø§Ø® Ø£Ù…ÙˆØ§Øª Ø£Ù„Ù… ÙˆØ§Ù‡Ø§Øª. Ø¨Ø³Ù…Ø© ÙŠÙ†Ø³Ù…Ø¹". There's a significant divergence.* We trust the starting word "ØµØ±Ø§Ø®" and its time.
        *   "Ø³Ø¯ ÙˆÙŠÙ†Ù‡Ø¯Ù…" -> Find "Ø³Ø¯ÙŠ." (\`87.68\`) -> \`[01:27.68]\` (User example \`[01:27.68]\`). *Note: JSON has "Ø³Ø¯ÙŠ. ÙˆÙŠÙ†Ù‡Ø¯Ù…".*
        *   "Ú†ÙÙ†Ù‡Ø§ Ø§Ù„Ø°Ø§Ø¨ Ù†Ø¸Ø±Ù‡Ø§ Ø§Ù„ØºØ§Ø¨ ÙˆÙŠ Ù…ÙˆØ¬ Ø§Ù„Ø¯Ù…Ø¹" -> Find "Ø¬ÙÙ†Ù‡Ø§" (\`91.239\`) -> \`[01:31.23]\` (User example \`[01:31.23]\`). *Note: JSON has "Ø¬ÙÙ†Ù‡Ø§ Ø§Ù„Ø°Ø§Øª. Ù†Ø¸Ø±Ù‡Ø§ Ø§Ù„ØºØ§Ø¨. ÙˆÙŠ Ù…ÙˆØ¬ Ø§Ù„Ø¯Ù…ÙŠØ¹."*
        *   "ØµÙˆØª ØµÙˆØª .. Ù…Ø§ ÙŠÙ„ØªÙ… Ø¨Ù‡ÙˆØ§Ù‡Ø§" -> Find first "ØµÙˆØª" (\`101.379\`) -> \`[01:41.37]\` (User example \`[01:41.37]\`). *Note: JSON has "ØµÙˆØª ØµÙˆØª Ù…Ø§ ÙŠÙ„ØªÙ…Ù… Ø¨Ù‡ÙˆØ§Ù‡Ø§."*
        *   "Ù…ÙˆØª Ù…ÙˆØª .. ØªØ­Ú†ÙŠ ÙˆÙŠØ±Ø¯ ØµØ¯Ø§Ù‡Ø§" -> Find first "Ù…ÙˆØª." (\`106.699\`) -> \`[01:46.69]\` (User example \`[01:46.69]\`). *Note: JSON has "Ù…ÙˆØª. Ù…ÙˆØª. ØªØ­ÙƒÙŠ. ÙŠØ±Ø¯ ØµØ¯Ø§Ù‡Ø§."*
        *   "ØªØµØ±Ø® Ø¨Ø§Ù„Ø­Ù„Ù…" -> Find "ØªØµØ±Ø®" (\`112.619\`) -> \`[01:52.61]\` (User example \`[01:52.61]\`). *Note: JSON has "ØªØµØ±Ø® Ø¨Ø§Ù„Ø­Ù†ÙŠÙ†." again.*

6.  **Implementation Details:**
    *   Need a function to format seconds into \`[mm:ss.xx]\`.
        *   \`minutes = floor(total_seconds / 60)\`
        *   \`seconds = total_seconds % 60\`
        *   Pad minutes and seconds with leading zeros if needed.
        *   Format seconds to two decimal places.
    *   Need to iterate through the accurate lines.
    *   For each accurate line, identify the *approximate* starting word(s) in the JSON stream. This seems to be the main challenge if done programmatically. *However*, since the user *provided the target output*, the mapping is already done. The task simplifies to:
        *   Read the target output line by line.
        *   Extract the timestamp from the target output.
        *   Extract the lyric text from the target output.
        *   *Find the start time in the original JSON that corresponds to the start of this lyric line.* This requires matching the *start* of the target lyric line to the words in the JSON.
        *   Use the timestamp found in the JSON for the final output, formatted correctly. *Correction:* The user *already provided* the correct timestamps in the *desired output example*. The task is just to verify that these timestamps correspond reasonably to the start of those lines in the *original JSON data*. The process above confirms this is the case.

7.  **Final Output Generation:** Since the process outlined in step 5 successfully reproduces the user's desired output format and timestamps using the provided JSON data and accurate lyrics, the final step is simply to present the resulting LRC lines.

8.  **Code Structure (Mental Outline):**

    \`\`\`python
    import math

    def format_time(seconds):
        minutes = math.floor(seconds / 60)
        sec = seconds % 60
        # Format seconds to two decimal places, ensuring leading zero if needed
        sec_str = "{:05.2f}".format(sec) # e.g., 5.1 becomes "05.10", 12.34 becomes "12.34"
        # Format minutes with leading zero
        min_str = "{:02d}".format(minutes)
        return f"[{min_str}:{sec_str}]"

    # Load JSON data (assuming it's parsed into a variable like 'data')
    words_times = data[0]['wordsTimes']

    # Filter out empty spaces (optional but good practice)
    # filtered_words = [item for item in words_times if item['text'].strip()]
    # For this specific task, we might not need filtering if we match carefully.

    accurate_lyrics_lines = [
        "ÙÙŠ Ù„ÙŠÙ„Ø© Ø¯Ù…Ø¹ Ø¬Ø§Ù†Øª Ø«Ú¯ÙŠÙ„Ù‡",
        "ÙØ²Øª Ù…Ù† Ø­Ù„Ù… Ø¹ÙŠÙ† Ø§Ù„Ø¹Ù„ÙŠÙ„Ø©",
        # ... all other lines
    ]

    # Define the mapping of accurate lines to JSON start times (as determined in step 5)
    # This mapping is crucial and derived by matching the start of accurate lines to JSON words.
    line_start_times = {
        "ÙÙŠ Ù„ÙŠÙ„Ø© Ø¯Ù…Ø¹ Ø¬Ø§Ù†Øª Ø«Ú¯ÙŠÙ„Ù‡": 31.239,
        "ÙØ²Øª Ù…Ù† Ø­Ù„Ù… Ø¹ÙŠÙ† Ø§Ù„Ø¹Ù„ÙŠÙ„Ø©": 36.719,
        "Ù„Ù…Ø­Øª ÙˆØ¬Ù‡ Ø§Ù„Ø­Ø³ÙŠÙ† Ø¨Ù…Ù†ÙŠØªÙ‡": 42.079,
        "Ø±Ø§Ø¯ ØªÙˆØ¯Ø¹Ù‡ Ø¨Ø³Ø§Ø¹Ø© Ø±Ø­ÙŠÙ„Ù‡": 47.399,
        "ÙˆØ±Ø¯Ù‡ ÙˆØ±ÙƒØ¶Øª Ù„Ù…Ø·Ø±Ø© Ø­Ù†ÙŠÙ†Ù‡": 52.459,
        "Ù…Ø³Ø­Øª Ø¯Ù…Ø¹Ù‡ Ù…Ù„ØªÙ…Ù‡ Ø§Ø¹Ù„Ù‡ Ø¹ÙŠÙ†Ù‡": 57.939,
        "Ù…Ù† Ø´Ø§ÙØª Ø±Ù…Ø­ Ø¨Ø¢Ø®Ø± Ù„Ø­ÙŠØªÙ‡": 63.299,
        "Ø±ÙƒØ¶Øª Ø¯ÙˆØ±Øª Ø¹Ù† Ø¬Ø³Ù…Ù‡ ÙˆÙŠÙ†Ù‡": 68.639,
        "ØªØµØ±Ø® Ø¨Ø§Ù„Ø­Ù„Ù…": 73.619, # First occurrence
        "ØµØ±Ø§Ø® Ø§Ù…ÙˆØ§Øª Ø§Ù„Ù… ÙˆØ§Ù‡Ø§Øª Ø¨Ø³ Ù…Ø§ ÙŠÙ†Ø³Ù…Ø¹": 77.119,
        "Ø³Ø¯ ÙˆÙŠÙ†Ù‡Ø¯Ù…": 87.68,
        "Ú†ÙÙ†Ù‡Ø§ Ø§Ù„Ø°Ø§Ø¨ Ù†Ø¸Ø±Ù‡Ø§ Ø§Ù„ØºØ§Ø¨ ÙˆÙŠ Ù…ÙˆØ¬ Ø§Ù„Ø¯Ù…Ø¹": 91.239,
        "ØµÙˆØª ØµÙˆØª .. Ù…Ø§ ÙŠÙ„ØªÙ… Ø¨Ù‡ÙˆØ§Ù‡Ø§": 101.379,
        "Ù…ÙˆØª Ù…ÙˆØª .. ØªØ­Ú†ÙŠ ÙˆÙŠØ±Ø¯ ØµØ¯Ø§Ù‡Ø§": 106.699,
        "ØªØµØ±Ø® Ø¨Ø§Ù„Ø­Ù„Ù…": 112.619 # Second occurrence
        # Need to handle the final lines from the accurate lyrics if they map to JSON times
        # "ØªØµØ±Ø® Ø¨Ø§Ù„Ø­Ù†ÙŠÙ†." at 116.839 -> maps to the last "ØªØµØ±Ø® Ø¨Ø§Ù„Ø­Ù„Ù…" or similar? Let's check user output.
        # The user output stops after the second "ØªØµØ±Ø® Ø¨Ø§Ù„Ø­Ù„Ù…". The last lines in the *accurate lyrics* provided are:
        # ØµÙˆØª ØµÙˆØª .. Ù…Ø§ ÙŠÙ„ØªÙ… Ø¨Ù‡ÙˆØ§Ù‡Ø§
        # Ù…ÙˆØª Ù…ÙˆØª .. ØªØ­Ú†ÙŠ ÙˆÙŠØ±Ø¯ ØµØ¯Ø§Ù‡Ø§
        # ØªØµØ±Ø® Ø¨Ø§Ù„Ø­Ù„Ù…
        # The user's *desired output* example ends after the *second* "ØªØµØ±Ø® Ø¨Ø§Ù„Ø­Ù„Ù…". Let's assume the provided accurate lyrics might be slightly longer than what the desired output covers, or the mapping needs careful checking for the very end.
        # Let's re-check the desired output:
        # [01:13.61]ØªØµØ±Ø® Ø¨Ø§Ù„Ø­Ù„Ù…  (maps to 73.619)
        # [01:17.11]ØµØ±Ø§Ø® Ø§Ù…ÙˆØ§Øª Ø§Ù„Ù… ÙˆØ§Ù‡Ø§Øª Ø¨Ø³ Ù…Ø§ ÙŠÙ†Ø³Ù…Ø¹ (maps to 77.119)
        # [01:27.68]Ø³Ø¯ ÙˆÙŠÙ†Ù‡Ø¯Ù… (maps to 87.68)
        # [01:31.23]Ú†ÙÙ†Ù‡Ø§ Ø§Ù„Ø°Ø§Ø¨ Ù†Ø¸Ø±Ù‡Ø§ Ø§Ù„ØºØ§Ø¨ ÙˆÙŠ Ù…ÙˆØ¬ Ø§Ù„Ø¯Ù…Ø¹ (maps to 91.239)
        # [01:41.37]ØµÙˆØª ØµÙˆØª .. Ù…Ø§ ÙŠÙ„ØªÙ… Ø¨Ù‡ÙˆØ§Ù‡Ø§ (maps to 101.379) - Wait, the provided accurate lyrics has this line *later*. Re-checking the structure.
        # Ah, the user provided:
        # 1. JSON
        # 2. Accurate Lyrics block
        # 3. Desired LRC Output block
        # The structure seems to be: Verse, Chorus, Verse, Chorus repeated?
        # Let's re-map using the *Desired Output* as the guide for which lines exist and their timestamps.

    # Map based on desired output lines and timestamps:
    desired_output_lines = [
        ("[00:31.23]", "ÙÙŠ Ù„ÙŠÙ„Ø© Ø¯Ù…Ø¹ Ø¬Ø§Ù†Øª Ø«Ú¯ÙŠÙ„Ù‡"),
        ("[00:36.71]", "ÙØ²Øª Ù…Ù† Ø­Ù„Ù… Ø¹ÙŠÙ† Ø§Ù„Ø¹Ù„ÙŠÙ„Ø©"),
        ("[00:42.07]", "Ù„Ù…Ø­Øª ÙˆØ¬Ù‡ Ø§Ù„Ø­Ø³ÙŠÙ† Ø¨Ù…Ù†ÙŠØªÙ‡"),
        ("[00:47.39]", "Ø±Ø§Ø¯ ØªÙˆØ¯Ø¹Ù‡ Ø¨Ø³Ø§Ø¹Ø© Ø±Ø­ÙŠÙ„Ù‡"),
        ("[00:52.45]", "ÙˆØ±Ø¯Ù‡ ÙˆØ±ÙƒØ¶Øª Ù„Ù…Ø·Ø±Ø© Ø­Ù†ÙŠÙ†Ù‡"),
        ("[00:57.93]", "Ù…Ø³Ø­Øª Ø¯Ù…Ø¹Ù‡ Ù…Ù„ØªÙ…Ù‡ Ø§Ø¹Ù„Ù‡ Ø¹ÙŠÙ†Ù‡"),
        ("[01:03.29]", "Ù…Ù† Ø´Ø§ÙØª Ø±Ù…Ø­ Ø¨Ø¢Ø®Ø± Ù„Ø­ÙŠØªÙ‡"),
        ("[01:08.63]", "Ø±ÙƒØ¶Øª Ø¯ÙˆØ±Øª Ø¹Ù† Ø¬Ø³Ù…Ù‡ ÙˆÙŠÙ†Ù‡"),
        ("[01:13.61]", "ØªØµØ±Ø® Ø¨Ø§Ù„Ø­Ù„Ù…"), # Time 73.619
        ("[01:17.11]", "ØµØ±Ø§Ø® Ø§Ù…ÙˆØ§Øª Ø§Ù„Ù… ÙˆØ§Ù‡Ø§Øª Ø¨Ø³ Ù…Ø§ ÙŠÙ†Ø³Ù…Ø¹"), # Time 77.119
        ("[01:27.68]", "Ø³Ø¯ ÙˆÙŠÙ†Ù‡Ø¯Ù…"), # Time 87.68 - Looks like JSON 'Ø³Ø¯ÙŠ.'
        ("[01:31.23]", "Ú†ÙÙ†Ù‡Ø§ Ø§Ù„Ø°Ø§Ø¨ Ù†Ø¸Ø±Ù‡Ø§ Ø§Ù„ØºØ§Ø¨ ÙˆÙŠ Ù…ÙˆØ¬ Ø§Ù„Ø¯Ù…Ø¹"), # Time 91.239 - Looks like JSON 'Ø¬ÙÙ†Ù‡Ø§'
        ("[01:41.37]", "ØµÙˆØª ØµÙˆØª .. Ù…Ø§ ÙŠÙ„ØªÙ… Ø¨Ù‡ÙˆØ§Ù‡Ø§"), # Time 101.379 - Looks like JSON first 'ØµÙˆØª'
        ("[01:46.69]", "Ù…ÙˆØª Ù…ÙˆØª .. ØªØ­Ú†ÙŠ ÙˆÙŠØ±Ø¯ ØµØ¯Ø§Ù‡Ø§"), # Time 106.699 - Looks like JSON first 'Ù…ÙˆØª.'
        ("[01:52.61]", "ØªØµØ±Ø® Ø¨Ø§Ù„Ø­Ù„Ù…") # Time 112.619 - Looks like JSON second 'ØªØµØ±Ø®'
    ]

    # Define the actual start times from JSON corresponding to these lines (verified manually)
    json_start_times = [
        31.239, 36.719, 42.079, 47.399, 52.459, 57.939, 63.299, 68.639,
        73.619, # ØªØµØ±Ø®
        77.119, # ØµØ±Ø§Ø®
        87.68,  # Ø³Ø¯ÙŠ.
        91.239, # Ø¬ÙÙ†Ù‡Ø§
        101.379, # ØµÙˆØª
        106.699, # Ù…ÙˆØª.
        112.619 # ØªØµØ±Ø®
        # The JSON has more words after 112.619, e.g., another "ØªØµØ±Ø® Ø¨Ø§Ù„Ø­Ù†ÙŠÙ†." at 116.839, and more after that up to 137.399.
        # The desired output stops here.
    ]

    # Generate the final LRC output
    lrc_output = []
    for i, (ts_example, line_text) in enumerate(desired_output_lines):
        start_time = json_start_times[i]
        formatted_ts = format_time(start_time)
        # Optional: Verify formatted_ts matches ts_example roughly
        # print(f"Comparing {formatted_ts} with {ts_example}")
        lrc_output.append(f"{formatted_ts}{line_text}")

    # Print the result
    # print("\\n".join(lrc_output))

    \`\`\`
9.  **Final Check:** The derived logic and manual matching process produce exactly the desired output provided by the user. The core is using the start time of the *first word* of the sequence in the JSON that corresponds to the *accurate lyric line*, and then using the *accurate lyric text* itself in the final output. The timestamps in the user's desired output correctly correspond (after formatting) to the start times identified in the JSON.`,
        },
        {
          text: `\`\`\`lrc
[00:31.23]ÙÙŠ Ù„ÙŠÙ„Ø© Ø¯Ù…Ø¹ Ø¬Ø§Ù†Øª Ø«Ú¯ÙŠÙ„Ù‡
[00:36.71]ÙØ²Øª Ù…Ù† Ø­Ù„Ù… Ø¹ÙŠÙ† Ø§Ù„Ø¹Ù„ÙŠÙ„Ø©
[00:42.07]Ù„Ù…Ø­Øª ÙˆØ¬Ù‡ Ø§Ù„Ø­Ø³ÙŠÙ† Ø¨Ù…Ù†ÙŠØªÙ‡
[00:47.39]Ø±Ø§Ø¯ ØªÙˆØ¯Ø¹Ù‡ Ø¨Ø³Ø§Ø¹Ø© Ø±Ø­ÙŠÙ„Ù‡
[00:52.45]ÙˆØ±Ø¯Ù‡ ÙˆØ±ÙƒØ¶Øª Ù„Ù…Ø·Ø±Ø© Ø­Ù†ÙŠÙ†Ù‡
[00:57.93]Ù…Ø³Ø­Øª Ø¯Ù…Ø¹Ù‡ Ù…Ù„ØªÙ…Ù‡ Ø§Ø¹Ù„Ù‡ Ø¹ÙŠÙ†Ù‡
[01:03.29]Ù…Ù† Ø´Ø§ÙØª Ø±Ù…Ø­ Ø¨Ø¢Ø®Ø± Ù„Ø­ÙŠØªÙ‡
[01:08.63]Ø±ÙƒØ¶Øª Ø¯ÙˆØ±Øª Ø¹Ù† Ø¬Ø³Ù…Ù‡ ÙˆÙŠÙ†Ù‡
[01:13.61]ØªØµØ±Ø® Ø¨Ø§Ù„Ø­Ù„Ù…
[01:17.11]ØµØ±Ø§Ø® Ø§Ù…ÙˆØ§Øª Ø§Ù„Ù… ÙˆØ§Ù‡Ø§Øª Ø¨Ø³ Ù…Ø§ ÙŠÙ†Ø³Ù…Ø¹
[01:27.68]Ø³Ø¯ ÙˆÙŠÙ†Ù‡Ø¯Ù…
[01:31.23]Ú†ÙÙ†Ù‡Ø§ Ø§Ù„Ø°Ø§Ø¨ Ù†Ø¸Ø±Ù‡Ø§ Ø§Ù„ØºØ§Ø¨ ÙˆÙŠ Ù…ÙˆØ¬ Ø§Ù„Ø¯Ù…Ø¹
[01:41.37]ØµÙˆØª ØµÙˆØª .. Ù…Ø§ ÙŠÙ„ØªÙ… Ø¨Ù‡ÙˆØ§Ù‡Ø§
[01:46.69]Ù…ÙˆØª Ù…ÙˆØª .. ØªØ­Ú†ÙŠ ÙˆÙŠØ±Ø¯ ØµØ¯Ø§Ù‡Ø§
[01:52.61]ØªØµØ±Ø® Ø¨Ø§Ù„Ø­Ù„Ù…
\`\`\``,
        },
      ],
    },
    {
      role: "user",
      parts: [
        {
          text: userInput,
        },
      ],
    },
  ];

  try {
    // 2. Use generateContentStream to stream the response
    const responseStream = await model.generateContentStream({
      contents,
    });

    // 3. Stream the response back to the client
    res.setHeader("Content-Type", "text/plain; charset=utf-8");
    for await (const chunk of responseStream.stream) {
      res.write(chunk.text());
    }
    res.end();
  } catch (err: any) {
    console.error(err);
    res.status(500).json({ error: err.message || "Something went wrong" });
  }
});
app.get("/", (req: Request, res: Response) => {
  res.send("Hello! This is the Gemini API server.");
});

const PORT = process.env.PORT || 3000;
app.listen(PORT, () => {
  console.log(`ðŸš€ Server running on http://localhost:${PORT}`);
});
